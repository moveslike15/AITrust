from gensim.models import Word2Vec
import matplotlib.pyplot as plt

# 단어와 2차원 X축의 값, Y축의 값을 입력받아 2차원 그래프를 그린다
def plot_2d_graph(vocabs, xs, ys):
    plt.figure(figsize=(8 ,6))
    plt.scatter(xs, ys, marker = 'o')
    for i, v in enumerate(vocabs):
        plt.annotate(v, xy=(xs[i], ys[i]))

sentences = [
                ['this', 'is', 'a',   'good',      'product'],
                ['it',   'is', 'a',   'excellent', 'product'],
                ['it',   'is', 'a',   'bad',       'product'],
                ['that', 'is', 'the', 'worst',     'product']
            ]

# 문장을 이용하여 단어와 벡터를 생성한다.
model = Word2Vec(sentences, size=300, window=3, min_count=1, workers=1)

# 단어벡터를 구한다.
word_vectors = model.wv

vocabs            = word_vectors.vocab.keys()
word_vectors_list = [word_vectors[v] for v in vocabs]

# 단어간 유사도를 확인하다
print(word_vectors.similarity(w1='it', w2='this'))

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
xys = pca.fit_transform(word_vectors_list)
xs = xys[:,0]
ys = xys[:,1]

plot_2d_graph(vocabs, xs, ys)



# 미리 학습된 모델과 병합
# https://github.com/mmihaltz/word2vec-GoogleNews-vectors
# URL에서 미리 학습된 모델을 다운로드 받는다.
file_name = 'GoogleNews-vectors-negative300.bin'
model.intersect_word2vec_format(fname=file_name, binary=True)

# 단어벡터를 구한다.
word_vectors = model.wv

vocabs            = word_vectors.vocab.keys()
word_vectors_list = [word_vectors[v] for v in vocabs]

# 단어간 유사도를 확인하다
print(word_vectors.similarity(w1='it', w2='this'))

from sklearn.decomposition import PCA
pca = PCA(n_components=2)
xys = pca.fit_transform(word_vectors_list)
xs = xys[:,0]
ys = xys[:,1]

plot_2d_graph(vocabs, xs, ys)

# 최종 모델을 저장한다.
model.save('word2vec.model')

# 저장한 모델을 읽어서 이용한다.
model = Word2Vec.load('word2vec.model')



#다음에서 가져온 그래프그리기:sallys.space/blog/2018/04/24/gensim-word2vec-embedding/

 viz_words = 2000
 word_vector = np.concatenate((model.wv.vectors[:viz_words//2,:], model.wv.vectors[11489:11489+viz_words//2,:]), axis=0)
 tsne = TSNE(n_components=3)
 embed_tsne = tsne.fit_transform(word_vector)

fig, ax = plt.subplots(figsize=(15,15))
for i in range(viz_words):
    if model.wv.index2word[i][-1] == 'N':
        plt.scatter(*embed_tsne[i,:],s=2,alpha=0.6, color='r')
        #plt.annotate(model.wv.index2word[i], (embed_tsne[i,0], embed_tsne[i,1]), alpha=0.6, fontsize=7)
    else:
        plt.scatter(*embed_tsne[i,:],s=2,alpha=0.6,color='b')
        #plt.annotate(model.wv.index2word[i], (embed_tsne[i,0], embed_tsne[i,1]), alpha=0.6, fontsize=7)
plt.savefig("seperate_15000_nolabel.png")
